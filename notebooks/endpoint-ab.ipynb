{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the namespaces based on _your_ deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the namespace of your baseline flow here. \n",
    "# You can find it in Metaflow GUI or in the command line print out when you do `python flow.py argo-workflows create`\n",
    "champ_namespace = \"production:mfprj-xsfdb3gtsiboqyrd-0-vqsy\" # \"production:mfprj-xsfdb3gtsiboqyrd-0-vqsy\"\n",
    "challenger_namespace = \"production:mfprj-cfyzlfzievjlmsf4-0-tbgz\" # \"production:mfprj-cfyzlfzievjlmsf4-0-tbgz\"\n",
    "# champ_namespace = ... # 'production:mfprj-xsfdb3gtsiboqyrd-0-vqsy'\n",
    "# challenger_namespace = ... # 'production:mfprj-cfyzlfzievjlmsf4-0-tbgz'\n",
    "\n",
    "# Don't change this unless you know what you are doing and want to change the uvicorn command.\n",
    "endpoint_uri_base = 'http://127.0.0.1:8000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow, namespace\n",
    "FLOW_NAME = 'TitanicSurvivalPredictor'\n",
    "\n",
    "namespace(challenger_namespace)\n",
    "run = Flow(FLOW_NAME).latest_successful_run\n",
    "model_type = run.data.model_type\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.predict() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict()\n",
      "\u001b[0;31mTypeError\u001b[0m: XGBClassifier.predict() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "run.data.model.predict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the endpoints to set model state on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8000/load-models?champ_namespace=production:mfprj-xsfdb3gtsiboqyrd-0-vqsy\n"
     ]
    }
   ],
   "source": [
    "use_challenger = False # If False, only load the champion model into memory on the server.\n",
    "\n",
    "if use_challenger:\n",
    "    slug = 'load-models?champ_namespace={}&challenger_namespace={}'.format(\n",
    "        champ_namespace, challenger_namespace)\n",
    "else:\n",
    "    slug = 'load-models?champ_namespace={}'.format(champ_namespace)\n",
    "\n",
    "load_models_endpoint = endpoint_uri_base + slug\n",
    "print(load_models_endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the uvicorn server\n",
    "\n",
    "Open a terminal and run:\n",
    "```sh\n",
    "uvicorn model-server:api\n",
    "```\n",
    "This needs to stay running while you complete the remaining cells of the notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the champion, and maybe challenger, model states on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline model as champion.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# A bit odd to make an API request to load models into memory, but isn't too different from what might happen in prod system.\n",
    "# It works well in this POC to show the core functionality of an A/B test.\n",
    "try: \n",
    "    response = requests.get(load_models_endpoint, verify=False, proxies={\"https\": endpoint_uri_base})\n",
    "    print(response.json())\n",
    "except requests.ConnectionError as e: \n",
    "    print(\"Did you run the server?!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random data point\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/titanic.csv\")\n",
    "\n",
    "inference_example = data.sample()\n",
    "idx = inference_example.index[0]\n",
    "true_target = inference_example['Survived'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = inference_example.to_json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request a prediction from server via basic A/B test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_challenger_model = False # if False, 80% traffic to champ model, 20% traffic to challenger model.\n",
    "\n",
    "pred_slug = 'get-pred?data={}'.format(payload)\n",
    "if force_challenger_model:\n",
    "    pred_slug += '&which_model=challenger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'endpoint_uri_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction_endpoint \u001b[39m=\u001b[39m endpoint_uri_base \u001b[39m+\u001b[39m pred_slug\n\u001b[1;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(prediction_endpoint, verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m: endpoint_uri_base})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endpoint_uri_base' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_endpoint = endpoint_uri_base + pred_slug\n",
    "try:\n",
    "    response = requests.get(prediction_endpoint, verify=False, proxies={\"https\": endpoint_uri_base})\n",
    "    print(response.json())\n",
    "except requests.ConnectionError as e: \n",
    "    print(\"Did you run the server?!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify A/B traffic is close to 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m      3\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(prediction_endpoint, verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m: endpoint_uri_base})\n\u001b[0;32m----> 4\u001b[0m     counts[response\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39m\u001b[39mmodel_used\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "counts = {\"champ\": 0, \"challenger\": 0}\n",
    "for _ in range(100):\n",
    "    response = requests.get(prediction_endpoint, verify=False, proxies={\"https\": endpoint_uri_base})\n",
    "    counts[response.json()['model_used']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'champ': 4, 'challenger': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-metaflow-corise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
